# Audio Transcription MCP - Docker Compose (Production with GPU)
# Usage: docker compose -f docker-compose.prod.yml up -d

services:
  audio-transcription:
    build:
      context: ..
      dockerfile: docker/Dockerfile.gpu
    image: audio-transcription-mcp:gpu
    container_name: audio-transcription-mcp
    
    # Environment configuration
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v3}
      - LANGUAGE=${LANGUAGE:-en}
      - MAX_FILE_SIZE_GB=${MAX_FILE_SIZE_GB:-1}
      - MCP_TRANSPORT=streamable-http
      - MCP_PORT=8080
      - CUDA_VISIBLE_DEVICES=0
    
    # Volume mounts
    volumes:
      - ../input:/input:ro          # Audio files (read-only)
      - ../output:/output           # Transcription results
      - ../models:/root/.cache      # Model cache (persistent)
    
    # Port mapping
    ports:
      - "8080:8080"
    
    # GPU support (NVIDIA)
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu, compute, utility]
    
    # Health check (longer start period for GPU model loading)
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    
    # Production settings
    restart: always
    
    # Resource limits
    # Uncomment and adjust based on your hardware
    # deploy:
    #   resources:
    #     limits:
    #       memory: 16G
    #     reservations:
    #       memory: 8G

# =============================================================================
# Network Configuration (optional)
# =============================================================================
# networks:
#   default:
#     driver: bridge
